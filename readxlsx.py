# analyze_bikeshare.py
# åŠŸèƒ½ï¼š
# 1) è¯»å– Capital Bikeshare çš„ CSV æ•°æ®ï¼ˆè‡ªåŠ¨è§£ææ—¶é—´ï¼‰
# 2) æ„å»ºå€Ÿè½¦/è¿˜è½¦"äº‹ä»¶æµ"ï¼Œè®¡ç®—æ¯ç«™ç‚¹çš„ç›¸å¯¹å‡€è½¦æ•°æ›²çº¿
# 3) ç»Ÿè®¡å„ç«™ç‚¹ï¼šMax_Positiveã€Min_Negativeã€Required_Docks_Est = max(abs(Max_Positive), abs(Min_Negative))
# 4) å¯¼å‡º station_capacity_estimates.csv
# 5) ç”Ÿæˆè®ºæ–‡å›¾ï¼ˆPNG 300dpi + SVGï¼‰ï¼šTop-N å®¹é‡æŸ±çŠ¶å›¾ï¼ˆå¸¦æ•°å€¼æ ‡ç­¾ï¼‰ã€å•ç«™ç‚¹æ›²çº¿ã€æ—¶é•¿åˆ†å¸ƒã€
#    æŒ‰å°æ—¶å€Ÿè½¦/è¿˜è½¦éœ€æ±‚ï¼ˆå‡å¸¦æ•°å€¼æ ‡ç­¾ï¼‰
# ä»…ç”¨ matplotlibï¼ˆæ—  seabornï¼‰ï¼Œæ¯ä¸ªå›¾å•ç‹¬ç”»å¸ƒï¼Œé€‚åˆè®ºæ–‡ç›´æ¥æ’å›¾

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from pathlib import Path

# ========== é…ç½® ==========
INPUT_CSV = "202503-capitalbikeshare-tripdata.csv"  # æ”¹æˆä½ çš„ CSV æ–‡ä»¶å
OUTPUT_DIR = Path("figures")                         # å›¾è¡¨è¾“å‡ºç›®å½•
TOP_N = 20                                           # Top-N ç«™ç‚¹
DPI = 300                                            # è®ºæ–‡å›¾åˆ†è¾¨ç‡
FONT_FAMILY = "DejaVu Sans"                          # å¦‚éœ€ä¸­æ–‡ï¼Œè¯·æ”¹ä¸ºç³»ç»Ÿä¸­çš„ä¸­æ–‡å­—ä½“åï¼Œä¾‹å¦‚ "SimHei"

# ========== åŸºç¡€è®¾ç½® ==========
plt.rcParams["font.family"] = FONT_FAMILY
plt.rcParams["axes.unicode_minus"] = False
OUTPUT_DIR.mkdir(exist_ok=True)

def read_and_clean(csv_path: str) -> pd.DataFrame:
    """è¯»å– CSVï¼Œè§£ææ—¶é—´ï¼ŒåšåŸºç¡€æ¸…æ´—"""
    df = pd.read_csv(csv_path)

    # åˆ—åæ£€æŸ¥ï¼ˆæ ¹æ®æ•°æ®å®é™…åˆ—åå¯è°ƒæ•´ï¼‰
    required_cols = ["started_at", "ended_at", "start_station_name", "end_station_name"]
    missing = [c for c in required_cols if c not in df.columns]
    if missing:
        raise ValueError(f"ç¼ºå°‘å¿…è¦åˆ—: {missing}. è¯·æ£€æŸ¥ CSV åˆ—åã€‚")

    # è‡ªåŠ¨è§£ææ—¶é—´ï¼›è§£æå¤±è´¥è®¾ä¸º NaT
    df["started_at"] = pd.to_datetime(df["started_at"], errors="coerce")
    df["ended_at"]   = pd.to_datetime(df["ended_at"], errors="coerce")
    # ä¸¢å¼ƒæ—¶é—´è§£æå¤±è´¥çš„è¡Œ
    before = len(df)
    df = df.dropna(subset=["started_at", "ended_at"]).copy()
    dropped = before - len(df)
    print(f"ğŸ§¹ ä¸¢å¼ƒæ— æ³•è§£ææ—¶é—´çš„è®°å½•: {dropped} æ¡")

    # å¦‚æœride_duration_minåˆ—ä¸å­˜åœ¨ï¼Œåˆ™è®¡ç®—éª‘è¡Œæ—¶é•¿
    if "ride_duration_min" not in df.columns:
        df["ride_duration_min"] = (df["ended_at"] - df["started_at"]).dt.total_seconds() / 60.0
        print("ğŸ“Š è®¡ç®—éª‘è¡Œæ—¶é•¿...")
    else:
        print("ğŸ“Š ä½¿ç”¨ç°æœ‰éª‘è¡Œæ—¶é•¿æ•°æ®...")

    return df

def build_events(df: pd.DataFrame) -> pd.DataFrame:
    """æ„å»ºå€Ÿè½¦/è¿˜è½¦äº‹ä»¶è¡¨å¹¶æŒ‰æ—¶é—´æ’åºï¼›è®¡ç®—æ¯ç«™ç‚¹ç´¯è®¡å‡€å˜åŒ–"""
    borrow_events = pd.DataFrame({
        "event_time": df["started_at"].values,
        "station": df["start_station_name"].values,
        "delta": -1
    })
    return_events = pd.DataFrame({
        "event_time": df["ended_at"].values,
        "station": df["end_station_name"].values,
        "delta": 1
    })
    events = pd.concat([borrow_events, return_events], ignore_index=True)
    events = events.dropna(subset=["event_time", "station"]).copy()
    events = events.sort_values("event_time", kind="mergesort").reset_index(drop=True)

    # è®¡ç®—æ¯ç«™ç‚¹çš„ç´¯è®¡å‡€å˜åŒ–ï¼ˆç›¸å¯¹é‡ï¼‰
    events["cum_change"] = events.groupby("station")["delta"].cumsum()
    return events

def estimate_capacity(events: pd.DataFrame, df: pd.DataFrame) -> pd.DataFrame:
    """ç»Ÿè®¡æ¯ç«™ç‚¹ max/min åŠ Required_Docks_Estï¼›åˆå¹¶ station_idï¼ˆè‹¥å­˜åœ¨ï¼‰"""
    agg = events.groupby("station")["cum_change"].agg(["max", "min"]).rename(
        columns={"max": "Max_Positive", "min": "Min_Negative"}
    )
    
    # ä¿®æ”¹å®¹é‡è®¡ç®—é€»è¾‘ï¼šå–æœ€å¤§æ­£æ•°å’Œæœ€å°è´Ÿæ•°ä¸­ç»å¯¹å€¼å¤§çš„
    agg["Required_Docks_Est"] = agg.apply(
        lambda row: max(abs(row["Max_Positive"]), abs(row["Min_Negative"])), 
        axis=1
    )

    # åˆå¹¶ station_idï¼ˆè‹¥ CSV åŒæ—¶å« start_station_id / end_station_idï¼‰
    id_cols = []
    if "start_station_id" in df.columns:
        id_cols.append(("start_station_name", "start_station_id"))
    if "end_station_id" in df.columns:
        id_cols.append(("end_station_name", "end_station_id"))

    station_id_map = None
    if id_cols:
        pieces = []
        for name_col, id_col in id_cols:
            tmp = df[[name_col, id_col]].dropna().drop_duplicates()
            tmp = tmp.rename(columns={name_col: "station", id_col: "station_id"})
            pieces.append(tmp)
        if pieces:
            station_id_map = pd.concat(pieces, ignore_index=True).drop_duplicates("station")

    if station_id_map is not None:
        result = agg.reset_index().merge(station_id_map, on="station", how="left")
        result = result[["station_id", "station", "Max_Positive", "Min_Negative", "Required_Docks_Est"]]
    else:
        result = agg.reset_index()
        result.insert(0, "station_id", np.nan)

    result = result.sort_values("Required_Docks_Est", ascending=False).reset_index(drop=True)
    return result

# ========== å‡ºå›¾ä¸å¯¼å‡º ==========
def save_fig(fig, filename_base: str):
    png_path = OUTPUT_DIR / f"{filename_base}.png"
    svg_path = OUTPUT_DIR / f"{filename_base}.svg"
    fig.savefig(png_path, dpi=DPI, bbox_inches="tight")
    fig.savefig(svg_path, bbox_inches="tight")
    plt.close(fig)
    print(f"ğŸ“ˆ å·²å¯¼å‡ºå›¾ï¼š{png_path}  |  {svg_path}")

def plot_topN_capacity_bars(res_df: pd.DataFrame, top_n: int = 20):
    """Top-N ç«™ç‚¹å®¹é‡ä¼°è®¡æŸ±çŠ¶å›¾ï¼ˆå¸¦æ•°å€¼æ ‡ç­¾ï¼‰
    å®¹é‡è®¡ç®—ï¼šmax(abs(Max_Positive), abs(Min_Negative))
    """
    top = res_df.head(top_n)
    labels = top["station"].astype(str).tolist()
    values = top["Required_Docks_Est"].astype(float).values

    fig, ax = plt.subplots(figsize=(10, 5))
    bars = ax.bar(range(len(values)), values)

    # æ•°å€¼æ ‡ç­¾ï¼ˆæ•´æ•°æ˜¾ç¤ºï¼‰
    for bar, val in zip(bars, values):
        ax.text(bar.get_x() + bar.get_width()/2,
                bar.get_height(),
                f"{int(round(val))}",
                ha='center', va='bottom', fontsize=8)

    ax.set_xticks(range(len(values)))
    ax.set_xticklabels(labels, rotation=60, ha="right")
    ax.set_ylabel("Estimated Required Docks (max of abs values)")
    ax.set_title(f"Top-{top_n} Stations by Estimated Required Docks")
    save_fig(fig, f"top{top_n}_required_docks")

def plot_station_capacity_curve(events_df: pd.DataFrame, station_name: str):
    """å•ç«™ç‚¹æ—¶é—´-ç›¸å¯¹å‡€è½¦æ•°æ›²çº¿"""
    sub = events_df.loc[events_df["station"] == station_name, ["event_time", "cum_change"]].copy()
    if sub.empty:
        print(f"âš ï¸ ç«™ç‚¹æ— æ•°æ®ï¼š{station_name}")
        return
    fig, ax = plt.subplots(figsize=(10, 4))
    ax.plot(sub["event_time"].values, sub["cum_change"].values)
    ax.set_xlabel("Time")
    ax.set_ylabel("Cumulative Net Bikes (relative)")
    ax.set_title(f"Capacity Curve (Relative) - {station_name}")
    save_fig(fig, f"capacity_curve_{station_name.replace('/', '_')[:60]}")

def plot_duration_hist(df_: pd.DataFrame, bins: int = 60):
    """éª‘è¡Œæ—¶é•¿åˆ†å¸ƒç›´æ–¹å›¾ï¼ˆè®¡æ•°ï¼‰"""
    vals = df_["ride_duration_min"].values
    fig, ax = plt.subplots(figsize=(8, 5))
    ax.hist(vals, bins=bins)
    ax.set_xlabel("Ride Duration (minutes)")
    ax.set_ylabel("Count")
    ax.set_title("Distribution of Ride Durations")
    save_fig(fig, "ride_duration_distribution")

def plot_hourly_demand(df_: pd.DataFrame):
    """æŒ‰å°æ—¶å€Ÿè½¦/è¿˜è½¦éœ€æ±‚æŸ±çŠ¶å›¾ï¼ˆå¸¦æ•°å€¼æ ‡ç­¾ï¼‰"""
    # å€Ÿè½¦
    df_b = df_[["started_at"]].copy()
    df_b["hour"] = df_b["started_at"].dt.hour
    borrow_cnt = df_b.groupby("hour").size()

    # è¿˜è½¦
    df_r = df_[["ended_at"]].copy()
    df_r["hour"] = df_r["ended_at"].dt.hour
    return_cnt = df_r.groupby("hour").size()

    hours = np.arange(24)
    b_vals = borrow_cnt.reindex(hours, fill_value=0).values
    r_vals = return_cnt.reindex(hours, fill_value=0).values

    # å€Ÿè½¦
    fig1, ax1 = plt.subplots(figsize=(8, 4))
    bars_b = ax1.bar(hours, b_vals)
    for bar, val in zip(bars_b, b_vals):
        ax1.text(bar.get_x() + bar.get_width()/2,
                 bar.get_height(),
                 f"{int(val)}", ha='center', va='bottom', fontsize=8)
    ax1.set_xticks(hours)
    ax1.set_xlabel("Hour of Day")
    ax1.set_ylabel("Borrow Count")
    ax1.set_title("Hourly Borrow Demand")
    save_fig(fig1, "hourly_borrow_demand")

    # è¿˜è½¦
    fig2, ax2 = plt.subplots(figsize=(8, 4))
    bars_r = ax2.bar(hours, r_vals)
    for bar, val in zip(bars_r, r_vals):
        ax2.text(bar.get_x() + bar.get_width()/2,
                 bar.get_height(),
                 f"{int(val)}", ha='center', va='bottom', fontsize=8)
    ax2.set_xticks(hours)
    ax2.set_xlabel("Hour of Day")
    ax2.set_ylabel("Return Count")
    ax2.set_title("Hourly Return Demand")
    save_fig(fig2, "hourly_return_demand")

def main():
    print("ğŸš´ æ•°æ®è¯»å–ä¸æ¸…æ´— ...")
    df = read_and_clean(INPUT_CSV)

    print("ğŸ§® æ„å»ºäº‹ä»¶å¹¶è®¡ç®—ç´¯è®¡å‡€å˜åŒ– ...")
    events = build_events(df)

    print("ğŸ“Š ä¼°è®¡å„ç«™ç‚¹å®¹é‡æŒ‡æ ‡ ...")
    result = estimate_capacity(events, df)

    # å¯¼å‡ºè¡¨æ ¼
    result_path = Path("station_capacity_estimates.csv")
    result.to_csv(result_path, index=False)
    print(f"âœ… å®¹é‡ç»Ÿè®¡å·²å¯¼å‡ºï¼š{result_path}")

    # ç”Ÿæˆè®ºæ–‡å›¾
    print("ğŸ–¼ï¸ ç”Ÿæˆè®ºæ–‡å›¾ ...")
    plot_topN_capacity_bars(result, top_n=TOP_N)
    plot_duration_hist(df, bins=60)
    plot_hourly_demand(df)

    # Top-N å‰ 3 ä¸ªç«™ç‚¹ï¼Œç»˜åˆ¶æ—¶é—´æ›²çº¿
    for s in result["station"].head(3).tolist():
        plot_station_capacity_curve(events, s)

    print("ğŸ‰ å®Œæˆï¼å›¾åƒåœ¨ ./figures/ ï¼Œè¡¨æ ¼åœ¨ station_capacity_estimates.csv")

if __name__ == "__main__":
    main()
